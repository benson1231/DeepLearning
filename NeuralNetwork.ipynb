{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWqUpBu9xey/gVbDvO5O02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benson1231/DeepLearning/blob/main/NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"drive/MyDrive/MachineLearning/insurance.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqiCq-ATxxn9",
        "outputId": "cfc25b40-2d07-4491-dd25-24033c0fd569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT8SQYdqwg7L",
        "outputId": "44a77a00-9afa-4d60-d9d3-b3e4af605f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               age         sex         bmi  children  smoker region_0rtheast  \\\n",
            "count   896.000000  896.000000  896.000000       896     896             896   \n",
            "unique   47.000000  455.000000    6.000000         2       2               2   \n",
            "top      -1.494934    0.293843   -0.912607         0       0           False   \n",
            "freq     53.000000   12.000000  383.000000       459     708             666   \n",
            "\n",
            "       region_0rthwest region_southeast region_southwest  \n",
            "count              896              896              896  \n",
            "unique               2                2                2  \n",
            "top              False            False            False  \n",
            "freq               670              667              685  \n",
            "               age         sex         bmi  children  smoker region_0rtheast  \\\n",
            "count   442.000000  442.000000  442.000000       442     442             442   \n",
            "unique   47.000000  312.000000    6.000000         2       2               2   \n",
            "top      -1.424533   -0.484495   -0.912607         1       0           False   \n",
            "freq     21.000000    5.000000  191.000000       225     356             348   \n",
            "\n",
            "       region_0rthwest region_southeast region_southwest  \n",
            "count              442              442              442  \n",
            "unique               2                2                2  \n",
            "top              False            False            False  \n",
            "freq               343              307              328  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "# 載入數據集\n",
        "dataset = pd.read_csv(data_path)\n",
        "# 選擇前6列作為特徵\n",
        "features = dataset.iloc[:,0:6]\n",
        "# 選擇最後一列作為目標標籤\n",
        "labels = dataset.iloc[:,-1]\n",
        "\n",
        "# 對類別型變數進行one-hot編碼\n",
        "features = pd.get_dummies(features)\n",
        "# 將數據分為訓練集和測試集\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "# 使用ColumnTransformer，對指定列進行標準化\n",
        "my_ct = ColumnTransformer([('scale', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "# 對訓練集應用標準化，並轉換為DataFrame格式\n",
        "features_train_scale = my_ct.fit_transform(features_train)\n",
        "# 對測試集應用訓練好的標準化轉換，並轉換為DataFrame格式\n",
        "features_test_scale = my_ct.transform(features_test)\n",
        "\n",
        "# ColumnTransformer返回的是numpy陣列，需轉換回pandas DataFrame\n",
        "features_train_scale = pd.DataFrame(features_train_scale, columns = features_train.columns)\n",
        "features_test_scale = pd.DataFrame(features_test_scale, columns = features_test.columns)\n",
        "\n",
        "# 列印數據統計摘要\n",
        "print(features_train_scale.describe())\n",
        "print(features_test_scale.describe())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def design_model(features):\n",
        "  model = Sequential()\n",
        "  return model\n",
        "\n",
        "dataset = pd.read_csv(data_path) #load the dataset\n",
        "features = dataset.iloc[:,0:6] #choose first 7 columns as features\n",
        "labels = dataset.iloc[:,-1] #choose the final column for prediction\n",
        "\n",
        "features = pd.get_dummies(features) #one-hot encoding for categorical variables\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) #split the data into training and test data\n",
        "\n",
        "#standardize\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "#invoke the function for our model design\n",
        "model = design_model(features_train)\n",
        "\n",
        "#print the layers\n",
        "print(model.layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0P9lINswphA",
        "outputId": "ac7b2863-0dc8-4c37-9391-51c193e3605d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def design_model(features):\n",
        "  model = Sequential(name = \"my_first_model\")\n",
        "  #get the number of features/dimensions in the data\n",
        "  num_features = features.shape[1]\n",
        "  #without hard-coding\n",
        "  input = layers.InputLayer(input_shape=(num_features,))\n",
        "  #adding the input layer\n",
        "  model.add(input)\n",
        "  return model\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(data_path) #load the dataset\n",
        "features = dataset.iloc[:,0:6] #choose first 7 columns as features\n",
        "labels = dataset.iloc[:,-1] #choose the final column for prediction\n",
        "\n",
        "features = pd.get_dummies(features) #one-hot encoding for categorical variables\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) #split the data into training and test data\n",
        "\n",
        "#standardize\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "#invoke the function for our model design\n",
        "model = design_model(features_train)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "R2kChHsDwrxx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "1f41ca08-b623-428c-abf6-9e9039c6667a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"my_first_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_first_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "tf.random.set_seed(35)  # for reproducibility\n",
        "\n",
        "def design_model(features):\n",
        "    model = Sequential(name=\"my_first_model\")\n",
        "    # Input layer\n",
        "    input = InputLayer(input_shape=(features.shape[1],))\n",
        "    model.add(input)\n",
        "    # Hidden layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    # Output layer\n",
        "    model.add(Dense(1))\n",
        "    # Compile model\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
        "    return model\n",
        "\n",
        "# 讀取資料\n",
        "dataset = pd.read_csv(data_path)\n",
        "\n",
        "# 特徵與目標變數\n",
        "features = dataset.iloc[:, 0:6]  # 前6列為特徵\n",
        "labels = dataset.iloc[:, -1]  # 最後一列為目標變數\n",
        "\n",
        "# One-hot 編碼處理類別型變數\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# 資料分割為訓練集和測試集\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    features, labels, test_size=0.33, random_state=42)\n",
        "\n",
        "# 標準化處理\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])],\n",
        "                       remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "# 確保數據轉換為數值格式\n",
        "features_train = np.array(features_train, dtype=np.float32)\n",
        "features_test = np.array(features_test, dtype=np.float32)\n",
        "labels_train = np.array(labels_train, dtype=np.float32)\n",
        "labels_test = np.array(labels_test, dtype=np.float32)\n",
        "\n",
        "# 設計模型\n",
        "model = design_model(features_train)\n",
        "print(model.summary())\n",
        "\n",
        "# 訓練模型\n",
        "model.fit(features_train, labels_train, epochs=40, batch_size=1, verbose=1)\n",
        "\n",
        "# 評估模型\n",
        "val_mse, val_mae = model.evaluate(features_test, labels_test, verbose=0)\n",
        "\n",
        "print(\"MAE: \", val_mae)"
      ],
      "metadata": {
        "id": "rwOXMEQLwr2Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96b51ec7-689a-4d3b-9f56-6df4589d1ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"my_first_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_first_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m1,280\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,409\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,409\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,409</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 284505792.0000 - mae: 11909.1807\n",
            "Epoch 2/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 105626720.0000 - mae: 7225.4492\n",
            "Epoch 3/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 77020864.0000 - mae: 6664.0410\n",
            "Epoch 4/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 59088804.0000 - mae: 5757.7139\n",
            "Epoch 5/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 47343892.0000 - mae: 5148.5635\n",
            "Epoch 6/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 41088344.0000 - mae: 4719.7939\n",
            "Epoch 7/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 38482092.0000 - mae: 4455.9580\n",
            "Epoch 8/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 37558920.0000 - mae: 4307.4536\n",
            "Epoch 9/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 37161388.0000 - mae: 4220.3906\n",
            "Epoch 10/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 36828176.0000 - mae: 4161.9067\n",
            "Epoch 11/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 36446740.0000 - mae: 4109.3960\n",
            "Epoch 12/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 36044612.0000 - mae: 4059.6633\n",
            "Epoch 13/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 35621780.0000 - mae: 4010.3455\n",
            "Epoch 14/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 35187624.0000 - mae: 3964.5825\n",
            "Epoch 15/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 34767612.0000 - mae: 3923.3643\n",
            "Epoch 16/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 34359152.0000 - mae: 3884.6292\n",
            "Epoch 17/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 33953936.0000 - mae: 3848.8916\n",
            "Epoch 18/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 33551608.0000 - mae: 3810.7961\n",
            "Epoch 19/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 33138972.0000 - mae: 3769.9851\n",
            "Epoch 20/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 32720528.0000 - mae: 3727.8115\n",
            "Epoch 21/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 32308468.0000 - mae: 3685.7495\n",
            "Epoch 22/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 31903508.0000 - mae: 3645.3687\n",
            "Epoch 23/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 31495154.0000 - mae: 3603.6028\n",
            "Epoch 24/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 31096028.0000 - mae: 3561.7476\n",
            "Epoch 25/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 30704236.0000 - mae: 3520.2388\n",
            "Epoch 26/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 30329146.0000 - mae: 3479.1790\n",
            "Epoch 27/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 29961040.0000 - mae: 3438.3660\n",
            "Epoch 28/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 29599144.0000 - mae: 3399.1462\n",
            "Epoch 29/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 29250376.0000 - mae: 3360.6956\n",
            "Epoch 30/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 28920534.0000 - mae: 3324.3154\n",
            "Epoch 31/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 28605194.0000 - mae: 3290.4614\n",
            "Epoch 32/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 28302374.0000 - mae: 3258.7000\n",
            "Epoch 33/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 28013486.0000 - mae: 3228.5820\n",
            "Epoch 34/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 27737174.0000 - mae: 3200.1772\n",
            "Epoch 35/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 27470952.0000 - mae: 3172.9128\n",
            "Epoch 36/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 27215172.0000 - mae: 3148.0896\n",
            "Epoch 37/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 26972880.0000 - mae: 3124.9080\n",
            "Epoch 38/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 26744872.0000 - mae: 3103.4873\n",
            "Epoch 39/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26529760.0000 - mae: 3082.5020\n",
            "Epoch 40/40\n",
            "\u001b[1m896/896\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26325566.0000 - mae: 3063.1465\n",
            "MAE:  2812.734619140625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN4VVXvdoO-Y",
        "outputId": "da455ff0-5aaa-40a9-8918-6c8dae8300c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer\n",
        "from model import design_model, features_train, labels_train\n",
        "\n",
        "#------------- GRID SEARCH --------------\n",
        "def do_grid_search():\n",
        "  batch_size = [6, 64]\n",
        "  epochs = [10, 50]\n",
        "  model = KerasRegressor(build_fn=design_model)\n",
        "  param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "  grid = GridSearchCV(estimator = model, param_grid=param_grid, scoring = make_scorer(mean_squared_error, greater_is_better=False),return_train_score = True)\n",
        "  grid_result = grid.fit(features_train, labels_train, verbose = 0)\n",
        "  print(grid_result)\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "  means = grid_result.cv_results_['mean_test_score']\n",
        "  stds = grid_result.cv_results_['std_test_score']\n",
        "  params = grid_result.cv_results_['params']\n",
        "  for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "  print(\"Traininig\")\n",
        "  means = grid_result.cv_results_['mean_train_score']\n",
        "  stds = grid_result.cv_results_['std_train_score']\n",
        "  for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "#------------- RANDOMIZED SEARCH --------------\n",
        "def do_randomized_search():\n",
        "  param_grid = {'batch_size': sp_randint(2, 16), 'nb_epoch': sp_randint(10, 100)}\n",
        "  model = KerasRegressor(build_fn=design_model)\n",
        "  grid = RandomizedSearchCV(estimator = model, param_distributions=param_grid, scoring = make_scorer(mean_squared_error, greater_is_better=False), n_iter = 12)\n",
        "  grid_result = grid.fit(features_train, labels_train, verbose = 0)\n",
        "  print(grid_result)\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "  means = grid_result.cv_results_['mean_test_score']\n",
        "  stds = grid_result.cv_results_['std_test_score']\n",
        "  params = grid_result.cv_results_['params']\n",
        "  for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "\n",
        "print(\"-------------- GRID SEARCH --------------------\")\n",
        "do_grid_search()\n",
        "print(\"-------------- RANDOMIZED SEARCH --------------------\")\n",
        "do_randomized_search()\n"
      ],
      "metadata": {
        "id": "Lnxdq9pDwr6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "8f7f137a-377d-457d-c75b-3d6b185162cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.wrappers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f1456db86e57>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp_randint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.wrappers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model import features_train, labels_train, fit_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from plotting import plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def design_model_dropout(X, learning_rate):\n",
        "    model = Sequential(name=\"my_first_model\")\n",
        "    input = tf.keras.Input(shape=(X.shape[1],))\n",
        "    model.add(input)\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(24, activation='relu'))\n",
        "    #------your code here!------\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    model.add(layers.Dense(1))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "    model.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
        "    return model\n",
        "\n",
        "def design_model_no_dropout(X, learning_rate):\n",
        "    model = Sequential(name=\"my_first_model\")\n",
        "    input = layers.InputLayer(input_shape=(X.shape[1],))\n",
        "    model.add(input)\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(24, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
        "    model.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
        "    return model\n",
        "\n",
        "#using the early stopping in fit_model\n",
        "learning_rate = 0.001\n",
        "num_epochs = 200\n",
        "#train the model without dropout\n",
        "history1 = fit_model(design_model_no_dropout(features_train, learning_rate), features_train, labels_train, learning_rate, num_epochs)\n",
        "#train the model with dropout\n",
        "history2 = fit_model(design_model_dropout(features_train, learning_rate), features_train, labels_train, learning_rate, num_epochs)\n",
        "\n",
        "plot(history1, 'static/images/no_dropout.png')\n",
        "\n",
        "plot(history2, 'static/images/with_dropout.png')\n",
        "\n",
        "import app #don't worry about this. This is to show you the plot in the browser."
      ],
      "metadata": {
        "id": "3vvhrU4fwr9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "f2dc69ab-bb74-42a5-9c0a-f2ef17fc35b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cebd2b1f2bdd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 確認是否使用 GPU\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# 測試 GPU 運算\n",
        "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
        "c = tf.matmul(a, b)\n",
        "print(c)\n"
      ],
      "metadata": {
        "id": "VoP5kSWHwsAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dea0b46-17f0-4da6-9c64-5b947201c680"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available:  []\n",
            "tf.Tensor(\n",
            "[[1. 3.]\n",
            " [3. 7.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMCOeKMmwsCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "id": "hK4vR5vTwsEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kMmLU_iCwsI2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}